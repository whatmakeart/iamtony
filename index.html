<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Face Tracking Example</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      overflow: hidden; /* Hide scrollbars */
      width: 100%;
      height: 100%;
      background: #222;
    }
    /* Make the canvas fill the entire screen */
    canvas {
      display: block;
    }
    /* For visibility in case the camera fails to load */
    #statusMessage {
      position: absolute;
      top: 1rem;
      left: 1rem;
      background: rgba(0,0,0,0.5);
      color: #0f0; /* Green text for clarity */
      padding: 0.5rem 1rem;
      font-family: sans-serif;
      z-index: 9999;
    }
  </style>
</head>
<body>
  <div id="statusMessage">Loading...</div>
  <!-- p5.js library -->
  <script src="https://cdn.jsdelivr.net/npm/p5@1.6.0/lib/p5.min.js"></script>
  <!-- ml5.js library (which uses face-api under the hood) -->
  <script src="https://cdn.jsdelivr.net/npm/ml5@0.12.2/dist/ml5.min.js"></script>

  <script>
    let video;
    let faceapi;
    let detections = [];

    // Face API options
    const detectionOptions = {
      withLandmarks: true,
      withDescriptors: false
    };

    function setup() {
      createCanvas(windowWidth, windowHeight);

      // Attempt to access the user-facing camera:
      // On some iOS Safari versions, "user" might not always work; 
      // you could try "environment" or remove facingMode for testing.
      video = createCapture({
        video: {
          facingMode: "user"
        },
        audio: false
      }, () => {
        console.log("Camera capture started!");
        document.getElementById("statusMessage").textContent = "Camera started, loading face model...";
      });

      // If for some reason camera fails:
      video.elt.addEventListener('error', (err) => {
        console.error('Video capture error:', err);
        document.getElementById("statusMessage").textContent = "Error: " + err.message;
      });

      // Resize video to fill the window (to match the canvas)
      video.size(width, height);
      video.hide();

      // Initialize ml5 face API
      faceapi = ml5.faceApi(video, detectionOptions, modelReady);
    }

    function modelReady() {
      console.log("Face API model loaded!");
      document.getElementById("statusMessage").textContent = "Face model loaded, detecting faces...";
      faceapi.detect(gotResults);
    }

    function gotResults(err, result) {
      if (err) {
        console.error(err);
        return;
      }
      detections = result;
      faceapi.detect(gotResults); // keep detecting
    }

    function draw() {
      background(0);

      // Draw the camera feed
      image(video, 0, 0, width, height);

      // If at least one face was detected
      if (detections && detections.length > 0) {
        // We'll look at the first detection only
        const { alignedRect } = detections[0];
        if (alignedRect) {
          const { x, y, width: w, height: h } = alignedRect._box;

          // Draw a pink rectangle around the face
          noFill();
          stroke('pink');
          strokeWeight(14);
          rect(x, y, w, h);

          // Pink text with yellow outline
          fill("pink");
          stroke("yellow");
          strokeWeight(4);
          textSize(60);
          textAlign(CENTER, CENTER);

          // Place text approximately at the forehead
          const foreheadY = y + 0.2 * h;
          text("I am Tony", x + w / 2, foreheadY);
        }
      }
    }

    function windowResized() {
      resizeCanvas(windowWidth, windowHeight);
      video.size(windowWidth, windowHeight);
    }
  </script>
</body>
</html>