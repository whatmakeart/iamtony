<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Face Tracking Example</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      overflow: hidden; /* Hide scrollbars */
      width: 100%;
      height: 100%;
    }
    canvas {
      display: block;
    }
    #switchCameraButton {
      position: absolute;
      top: 20px;
      left: 20px;
      padding: 10px 20px;
      background-color: rgba(0, 0, 0, 0.5);
      color: white;
      border: none;
      border-radius: 5px;
      font-size: 16px;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <!-- p5.js library -->
  <script src="https://cdn.jsdelivr.net/npm/p5@1.6.0/lib/p5.min.js"></script>
  <!-- ml5.js library (which uses face-api under the hood) -->
  <script src="https://cdn.jsdelivr.net/npm/ml5@0.12.2/dist/ml5.min.js"></script>

  <button id="switchCameraButton">Switch Camera</button>

  <script>
    let video;
    let faceapi;
    let detections = [];
    let mustacheImg;
    let sunglassesImg;
    let rainbowColorIndex = 0;
    let isFrontCamera = true; // Track camera state (front or back)

    // Configure ml5 Face API
    const detectionOptions = {
      withLandmarks: true,
      withDescriptors: false
    };

    function preload() {
      // Load mustache and sunglasses images
      mustacheImg = loadImage('https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Mustache_Clipart_1.svg/1024px-Mustache_Clipart_1.svg.png');
      sunglassesImg = loadImage('https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Sunglasses_Transparent_Background.png/620px-Sunglasses_Transparent_Background.png');
    }

    function setup() {
      // Create full-window canvas
      createCanvas(windowWidth, windowHeight);

      // Set up button click event to switch cameras
      const switchCameraButton = document.getElementById('switchCameraButton');
      switchCameraButton.addEventListener('click', switchCamera);

      // Start video capture based on device type
      startVideo();
    }

    function startVideo() {
      const videoOptions = {
        video: {
          facingMode: isFrontCamera ? "user" : "environment"
        },
        audio: false
      };

      // Start video capture with the selected camera
      video = createCapture(videoOptions);
      video.size(width, height);
      video.hide(); // Hide the HTML video element (we'll draw it to canvas)

      // Initialize face API with the video
      faceapi = ml5.faceApi(video, detectionOptions, modelReady);
    }

    function modelReady() {
      console.log("Face API model loaded!");
      // Start detecting faces continuously
      faceapi.detect(gotResults);
    }

    function gotResults(err, result) {
      if (err) {
        console.error(err);
        return;
      }
      detections = result;
      // Keep detecting faces
      faceapi.detect(gotResults);
    }

    function switchCamera() {
      // Switch between front and back camera
      isFrontCamera = !isFrontCamera;
      video.remove(); // Remove the previous video element
      startVideo(); // Restart the video capture with the new camera
    }

    function draw() {
      // Draw the video to the background
      background(0);
      image(video, 0, 0, width, height);

      // If we have at least one face detected
      if (detections.length > 0) {
        // First face (Tony's face)
        let { alignedRect } = detections[0];
        let { x, y, width: w, height: h } = alignedRect._box;

        // Rainbow outline animation
        noFill();
        strokeWeight(10);
        stroke(lerpColor(color(255, 0, 0), color(255, 255, 0), rainbowColorIndex));
        rect(x, y, w, h); // Draw rectangle around face

        // Draw text: Pink fill, yellow outline
        fill("pink");
        stroke("yellow");
        strokeWeight(15);
        textSize(60);
        textAlign(CENTER);

        // Roughly place on the forehead (somewhere in the top portion of the bounding box)
        let foreheadY = y + 0.2 * h;
        text("I am Tony", x + w / 2, foreheadY);

        // Add a better-shaped mustache under the nose of the first face
        let mustacheWidth = w * 0.6;
        let mustacheHeight = h * 0.12;
        image(mustacheImg, x + w / 6, y + h * 0.75, mustacheWidth, mustacheHeight);
      }

      // If we have a second face detected
      if (detections.length > 1) {
        let { alignedRect } = detections[1];
        let { x, y, width: w, height: h } = alignedRect._box;

        // Rainbow outline animation for the second face
        noFill();
        strokeWeight(10);
        stroke(lerpColor(color(0, 255, 0), color(0, 0, 255), rainbowColorIndex));
        rect(x, y, w, h); // Draw rectangle around second face

        // Draw more realistic sunglasses on the second face
        let glassesWidth = w * 0.8;
        let glassesHeight = h * 0.25;
        image(sunglassesImg, x + w / 6, y + h * 0.2, glassesWidth, glassesHeight);

        // Draw text for the second face
        fill("cyan");
        stroke("red");
        strokeWeight(10);
        textSize(50);
        textAlign(CENTER);
        text("Not Tony", x + w / 2, y + h * 0.1);
      }

      // Increment rainbow color index to create the effect
      rainbowColorIndex += 0.01;
      if (rainbowColorIndex > 1) rainbowColorIndex = 0; // Loop back to 0
    }

    // Adjust canvas if the window is resized
    function windowResized() {
      resizeCanvas(windowWidth, windowHeight);
      video.size(windowWidth, windowHeight);
    }
  </script>
</body>
</html>
